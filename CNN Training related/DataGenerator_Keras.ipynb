{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13968\n",
      "13968\n",
      "x_train shape: (12570, 25, 44, 1)\n",
      "12570 train samples\n",
      "1396 test samples\n",
      "Train on 12570 samples, validate on 1396 samples\n",
      "Epoch 1/12\n",
      "12570/12570 [==============================] - 88s 7ms/step - loss: 3.2765 - accuracy: 0.1984 - val_loss: 2.0379 - val_accuracy: 0.4656\n",
      "Epoch 2/12\n",
      "12570/12570 [==============================] - 87s 7ms/step - loss: 2.0526 - accuracy: 0.4502 - val_loss: 1.4502 - val_accuracy: 0.6046\n",
      "Epoch 3/12\n",
      "12570/12570 [==============================] - 87s 7ms/step - loss: 1.5269 - accuracy: 0.5864 - val_loss: 1.2107 - val_accuracy: 0.6855\n",
      "Epoch 4/12\n",
      "12570/12570 [==============================] - 86s 7ms/step - loss: 1.2641 - accuracy: 0.6591 - val_loss: 0.9768 - val_accuracy: 0.7385\n",
      "Epoch 5/12\n",
      "12570/12570 [==============================] - 87s 7ms/step - loss: 1.0478 - accuracy: 0.7161 - val_loss: 0.8544 - val_accuracy: 0.7787\n",
      "Epoch 6/12\n",
      "12570/12570 [==============================] - 87s 7ms/step - loss: 0.9306 - accuracy: 0.7454 - val_loss: 0.8165 - val_accuracy: 0.7801\n",
      "Epoch 7/12\n",
      "12570/12570 [==============================] - 86s 7ms/step - loss: 0.8175 - accuracy: 0.7796 - val_loss: 0.8277 - val_accuracy: 0.7837\n",
      "Epoch 8/12\n",
      "12570/12570 [==============================] - 86s 7ms/step - loss: 0.7273 - accuracy: 0.8033 - val_loss: 0.7593 - val_accuracy: 0.8130\n",
      "Epoch 9/12\n",
      "12570/12570 [==============================] - 87s 7ms/step - loss: 0.6839 - accuracy: 0.8122 - val_loss: 0.7200 - val_accuracy: 0.8231\n",
      "Epoch 10/12\n",
      "12570/12570 [==============================] - 88s 7ms/step - loss: 0.6125 - accuracy: 0.8302 - val_loss: 0.7284 - val_accuracy: 0.8173\n",
      "Epoch 11/12\n",
      "12570/12570 [==============================] - 87s 7ms/step - loss: 0.5797 - accuracy: 0.8424 - val_loss: 0.7041 - val_accuracy: 0.8360\n",
      "Epoch 12/12\n",
      "12570/12570 [==============================] - 87s 7ms/step - loss: 0.5158 - accuracy: 0.8588 - val_loss: 0.6935 - val_accuracy: 0.8288\n",
      "Test loss: 0.6934874653816223\n",
      "Test accuracy: 0.8287965655326843\n",
      "save weights\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 30\n",
    "num_classes = 100\n",
    "epochs = 12\n",
    "img_rows, img_cols = 25, 44\n",
    "\n",
    "rpath = \"F:/Google Drive/User_Backup/Reversed_images\"\n",
    "#wpath = \"F:/Google Drive/User_Backup/training\"\n",
    "image = []\n",
    "answer = []\n",
    "onlyfolders = [f for f in listdir(rpath)]\n",
    "for folder in onlyfolders:\n",
    "    # print(rpath+\"/\"+folder)\n",
    "    npath = rpath +\"/\"+ folder\n",
    "    onlyfiles = [f for f in listdir(npath) if isfile(join(npath, f)) and f[-4:] == \".png\"]\n",
    "    for file in onlyfiles:\n",
    "        filename = npath + \"/\" + file\n",
    "        img = cv2.imread(filename, 0)\n",
    "        dim = (img_rows, img_cols)\n",
    "        img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        image.append(img)\n",
    "        p = file.find(\"_\")\n",
    "        if not file[:p].isnumeric():\n",
    "            print(filename)\n",
    "        answer.append(int(file[:p]))\n",
    "print(len(image))\n",
    "print(len(answer))\n",
    "train_image, answer = shuffle(image, answer)\n",
    "i = 0\n",
    "\n",
    "x_train = np.array(train_image[:12570])\n",
    "x_test = np.array(train_image[12571:13967])\n",
    "y_train = np.array(answer[:12570])\n",
    "y_test = np.array(answer[12571:13967])\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = model_from_json(open('F:/Google Drive/User_Backup/model/cnn_model.json').read())\n",
    "model.load_weights('F:/Google Drive/User_Backup/model/cnn_model_weights.hdf5')\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.Adadelta(),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save_weights('F:/Google Drive/User_Backup/model/cnn_model_weights3.hdf5')\n",
    "json_string = model.to_json()\n",
    "open('F:/Google Drive/User_Backup/model/cnn_model3.json', 'w').write(json_string)\n",
    "yaml_string = model.to_yaml()\n",
    "open('F:/Google Drive/User_Backup/model/cnn_model3.yaml', 'w').write(yaml_string)\n",
    "print('save weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/Google Drive/User_Backup/Reversed_images/A_20190926_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191002_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191003_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191009_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191010_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191016_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191017_Omei\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191017_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191022_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191023_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191029_EZ\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191030_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191031_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191106_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191107_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191113_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191120_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191121_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191204_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/A_20191212_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20190922_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20190926_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191002_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191003_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191009_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191010_Omei\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191016_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191017_Omei\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191017_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191021_Omei\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191023_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191029_TRMS\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191030_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191031_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191107_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191113_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191114_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191116_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191120_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191121_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191204_ACME\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191205_Tulip\n",
      "F:/Google Drive/User_Backup/Reversed_images/M_20191212_tULIP\n",
      "F:/Google Drive/User_Backup/Reversed_images/S_20191010_Omei\n",
      "F:/Google Drive/User_Backup/Reversed_images/S_20191014_LACS\n",
      "F:/Google Drive/User_Backup/Reversed_images/S_20191014_Noam\n",
      "F:/Google Drive/User_Backup/Reversed_images/S_20191021_LACS\n",
      "F:/Google Drive/User_Backup/Reversed_images/S_20191028_LACS\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator,  img_to_array, load_img\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.1,fill_mode=\"nearest\",zoom_range=0.15,shear_range=15 )\n",
    "\n",
    "\n",
    "batch_size = 30\n",
    "num_classes = 100\n",
    "epochs = 12\n",
    "img_rows, img_cols = 25, 44\n",
    "\n",
    "rpath = \"F:/Google Drive/User_Backup/Reversed_images\"\n",
    "wpath = \"F:/Google Drive/User_Backup/DataGeneration\"\n",
    "image = []\n",
    "answer = []\n",
    "onlyfolders = [f for f in listdir(rpath)]\n",
    "for folder in onlyfolders:\n",
    "    print(rpath+\"/\"+folder)\n",
    "    npath = rpath +\"/\"+ folder\n",
    "    onlyfiles = [f for f in listdir(npath) if isfile(join(npath, f)) and f[-4:] == \".png\"]\n",
    "    for file in onlyfiles:\n",
    "        filename = npath + \"/\" + file\n",
    "        img = load_img(filename)\n",
    "        img = np.array(img)\n",
    "        x = img[np.newaxis]\n",
    "        p = file.find(\"_\")\n",
    "        prefix = file[:p] + \"_\"\n",
    "        gen = datagen.flow(x, batch_size=1, save_to_dir=wpath,\n",
    "                   save_prefix=prefix, save_format='png')\n",
    "        for i in range(20):\n",
    "            next(gen)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
