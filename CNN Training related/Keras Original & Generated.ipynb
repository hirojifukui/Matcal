{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676221\n",
      "676221\n",
      "x_train shape: (608597, 25, 44, 1)\n",
      "608597 train samples\n",
      "67621 test samples\n",
      "Train on 608597 samples, validate on 67621 samples\n",
      "Epoch 1/8\n",
      "608597/608597 [==============================] - 2691s 4ms/step - loss: 0.9964 - accuracy: 0.7345 - val_loss: 0.2682 - val_accuracy: 0.9240\n",
      "Epoch 2/8\n",
      "608597/608597 [==============================] - 2621s 4ms/step - loss: 0.3364 - accuracy: 0.9060 - val_loss: 0.1685 - val_accuracy: 0.9530\n",
      "Epoch 3/8\n",
      "608597/608597 [==============================] - 2844s 5ms/step - loss: 0.2593 - accuracy: 0.9282 - val_loss: 0.1370 - val_accuracy: 0.9630\n",
      "Epoch 4/8\n",
      "608597/608597 [==============================] - 2741s 5ms/step - loss: 0.2266 - accuracy: 0.9378 - val_loss: 0.1116 - val_accuracy: 0.9700\n",
      "Epoch 5/8\n",
      "608597/608597 [==============================] - 2760s 5ms/step - loss: 0.2080 - accuracy: 0.9434 - val_loss: 0.1225 - val_accuracy: 0.9680\n",
      "Epoch 6/8\n",
      "608597/608597 [==============================] - 2887s 5ms/step - loss: 0.1983 - accuracy: 0.9461 - val_loss: 0.1155 - val_accuracy: 0.9705\n",
      "Epoch 7/8\n",
      "608597/608597 [==============================] - 2764s 5ms/step - loss: 0.1907 - accuracy: 0.9490 - val_loss: 0.0954 - val_accuracy: 0.9747\n",
      "Epoch 8/8\n",
      "608597/608597 [==============================] - 2734s 4ms/step - loss: 0.1855 - accuracy: 0.9504 - val_loss: 0.0944 - val_accuracy: 0.9748\n",
      "Test loss: 0.09436974213666496\n",
      "Test accuracy: 0.9747563600540161\n",
      "save weights\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 100\n",
    "num_classes = 100\n",
    "epochs = 8\n",
    "\n",
    "# input image dimensions\n",
    "#img_rows, img_cols = 28, 28\n",
    "img_rows, img_cols = 25, 44\n",
    " \n",
    "rpath = \"F:/Google Drive/User_Backup/training\"\n",
    "#wpath = \"F:/Google Drive/User_Backup/training\"\n",
    "h_max, w_max, h_out, w_out = 75, 132, 25, 44\n",
    "image = []\n",
    "answer = []\n",
    "for j in range (0, 100):\n",
    "#   print(j)\n",
    "    for k in range (5000):\n",
    "        tpath = rpath + \"/\" + str(j) + \"/\" + str(k) + \".png\"\n",
    "        img = cv2.imread(tpath, 0)\n",
    "        image.append(img)\n",
    "        answer.append(j)\n",
    "npath = \"F:/Google Drive/User_Backup/DataGeneration\"\n",
    "onlyfiles = [f for f in listdir(npath) if isfile(join(npath, f)) and f[-4:] == \".png\"]\n",
    "for file in onlyfiles:\n",
    "    filename = npath + \"/\" + file\n",
    "    img = cv2.imread(filename, 0)\n",
    "    image.append(img)\n",
    "    p = file.find(\"_\")\n",
    "    answer.append(int(file[:p]))\n",
    "print(len(image))\n",
    "print(len(answer))\n",
    "train_image, answer = shuffle(image, answer)\n",
    "i = 0\n",
    "\n",
    "x_train = np.array(train_image[:608597])\n",
    "x_test = np.array(train_image[608598:676219])\n",
    "y_train = np.array(answer[:608597])\n",
    "y_test = np.array(answer[608598:676219])\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save_weights('F:/Google Drive/User_Backup/model/cnn_model_weights4.hdf5')\n",
    "json_string = model.to_json()\n",
    "open('F:/Google Drive/User_Backup/model/cnn_model4.json', 'w').write(json_string)\n",
    "yaml_string = model.to_yaml()\n",
    "open('F:/Google Drive/User_Backup/model/cnn_model4.yaml', 'w').write(yaml_string)\n",
    "print('save weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
